{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import all the packages we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run the following code to make sure all the functions can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outlier_finder(data):\n",
    "    \"\"\"\n",
    "    find outliers in the data\n",
    "    return the indexes of the outliers\n",
    "    \"\"\"\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        data = np.array(data)\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    upper_bound = q3 + 1.5 * (q3 - q1)\n",
    "    lower_bound = q1 - 1.5 * (q3 - q1)\n",
    "    outliers = []\n",
    "    for index, item in enumerate(data):\n",
    "        if item > upper_bound or item < lower_bound:\n",
    "            outliers.append(index)\n",
    "    return outliers\n",
    "\n",
    "def replace_val(data, outliers, mode='max'):\n",
    "    \"\"\"\n",
    "    modify the outliers by the mean or max value of the rest data\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    for i in range(len(data)):\n",
    "        if i not in outliers:\n",
    "            data_list.append(data[i])\n",
    "    if mode == 'max':\n",
    "        return np.max(data_list)\n",
    "    elif mode == 'mean':\n",
    "        return np.mean(data_list)\n",
    "    else:\n",
    "        print ('Node such mode')\n",
    "\n",
    "class ProgressBar:\n",
    "    \"\"\"\n",
    "    make a progress bar to show the progress\n",
    "    \"\"\"\n",
    "    def __init__(self, count = 0, total = 0, width = 50):\n",
    "        self.count = count\n",
    "        self.total = total\n",
    "        self.width = width\n",
    "        self.progress = 0\n",
    "    \n",
    "    def move(self):\n",
    "        self.count += 1\n",
    "    \n",
    "    def log(self):\n",
    "        new_progress = self.width * self.count // self.total\n",
    "        if new_progress > self.progress:\n",
    "            sys.stdout.write(' ' * (self.width + 9) + '\\r')\n",
    "            sys.stdout.flush()\n",
    "            self.progress = new_progress\n",
    "            sys.stdout.write('{0:3}/{1:3}: '.format(self.count, self.total))\n",
    "            sys.stdout.write('#' * self.progress + '-' * int(self.width - self.progress) + '\\r')\n",
    "            if self.progress == self.width:\n",
    "                sys.stdout.write('\\n')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "def execute_func(input_file, output_file, mode='max'):\n",
    "    \"\"\"\n",
    "    modify all the outliers\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    cols = ['predict_' + str(i) for i in range (1, 11, 1)]\n",
    "    df_predict_vals = df[cols]\n",
    "\n",
    "    t1 = time.time()\n",
    "    d ={}\n",
    "    bar = ProgressBar(total = df_predict_vals.shape[0])\n",
    "    for index, row in df_predict_vals.iterrows():\n",
    "        outliers = outlier_finder( row )\n",
    "        if outliers:\n",
    "            new_val = replace_val(row, outliers, mode)\n",
    "            for outlier in outliers:\n",
    "                row[outlier] = new_val\n",
    "            d[index] = outliers\n",
    "        bar.move()\n",
    "        bar.log()\n",
    "    t2 = time.time()\n",
    "    print ('cost time {0:.2f}min'.format((t2 - t1) / 60))\n",
    "    print ('{}/{} rows are modified'.format(len(d), df_predict_vals.shape[0]))\n",
    "\n",
    "    df_features = pd.concat([df[['xid', 'yid', 'hour']], df_predict_vals], axis=1)\n",
    "    df_features.to_csv(output_file, index=False)\n",
    "    del df, df_predict_vals, df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split the data into 5 files according to the days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Day 6\n",
      "Day 6 done! cost 6.26 min\n",
      "start Day 7\n",
      "Day 7 done! cost 6.07 min\n",
      "start Day 8\n",
      "Day 8 done! cost 5.63 min\n",
      "start Day 9\n",
      "Day 9 done! cost 5.47 min\n",
      "start Day 10\n",
      "Day 10 done! cost 5.44 min\n"
     ]
    }
   ],
   "source": [
    "# data directory\n",
    "file_path = '../dataset'\n",
    "\n",
    "for i in range(5, 10, 1):\n",
    "    time_start = time.time()\n",
    "    \n",
    "    # dateset name\n",
    "    file_name = 'ForecastDataforTesting_day' + str(i + 1) + '.csv'\n",
    "    \n",
    "    # judge if the file is already there\n",
    "    file_list = [x[2] for x in os.walk(file_path)][0]\n",
    "    if file_name in file_list:\n",
    "        print ('{} already exists'.format(file_name))\n",
    "        continue\n",
    "    \n",
    "    print ('start Day {}'.format(i + 1))\n",
    "    \n",
    "    # load the test data\n",
    "    df_predicting_train = pd.read_csv('../dataset/ForecastDataforTesting_201802.csv', chunksize=1e7)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for chunk in df_predicting_train:\n",
    "        df = pd.concat([df, chunk[chunk.date_id == i + 1]])\n",
    "    \n",
    "    # store data\n",
    "    df.to_csv(os.path.join(file_path, file_name), index=False)\n",
    "    del df\n",
    "    \n",
    "    time_end = time.time()\n",
    "    print ('Day {0} done! cost {1:.2f} min'.format(i + 1, (time_end - time_start) / 60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Change the data into the format we want\n",
    "\n",
    "### There may be a memory error if you are using a PC with low memory storage (8G may be just fine, 12G is recommended), don't worry, just close other programs you are running, restart the kernel and run it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start day 6, mode wind\n",
      "wind_data_day6.csv is already there\n",
      "start day 6, mode rainfall\n",
      "rainfall_data_day6.csv is already there\n",
      "start day 7, mode wind\n",
      "wind_data_day7.csv is already there\n",
      "start day 7, mode rainfall\n",
      "rainfall_data_day7.csv is already there\n",
      "start day 8, mode wind\n",
      "wind_data_day8.csv is already there\n",
      "start day 8, mode rainfall\n",
      "rainfall_data_day8.csv is already there\n",
      "start day 9, mode wind\n",
      "cost 2.33min\n",
      "start day 9, mode rainfall\n",
      "cost 2.94min\n",
      "start day 10, mode wind\n",
      "cost 3.55min\n",
      "start day 10, mode rainfall\n",
      "cost 4.17min\n"
     ]
    }
   ],
   "source": [
    "def find_index_by_xyh(xid, yid, hour):\n",
    "    return (hour-3)*548*421 + (xid-1)*421 + yid - 1\n",
    "\n",
    "def replace_index(index):\n",
    "    xyh = index.split('_')\n",
    "    return find_index_by_xyh(int(xyh[0]), int(xyh[1]), int(xyh[2]))\n",
    "\n",
    "\n",
    "if not os.path.exists('../dataset/x_y_hour.pickle'):\n",
    "    t1 = time.time()\n",
    "    df = pd.read_csv('../dataset/ForecastDataforTesting_day1.csv')\n",
    "    df['x_y_hour'] = df['xid'].astype(int).astype(str) + '_' + df['yid'].astype(int).astype(str)  + '_' + df['hour'].astype(int).astype(str) \n",
    "    with open('../dataset/x_y_hour.pickle', 'wb') as f:\n",
    "        pickle.dump(df['x_y_hour'], f)\n",
    "    t2 = time.time()\n",
    "    print ('cost {0:.2f}min to get x_y_hour.pickle'.format((t2 - t1) / 60))\n",
    "    del df\n",
    "\n",
    "for day in range(6, 11, 1):\n",
    "    for mode in ['wind', 'rainfall']:\n",
    "        print ('start day {}, mode {}'.format(day, mode))\n",
    "        if os.path.exists('../dataset/' + mode + '_data_day' + str(day) + '.csv'):\n",
    "            print (mode + '_data_day' + str(day) + '.csv is already there' )\n",
    "            continue\n",
    "        t1 = time.time()\n",
    "        df = pd.read_csv('../dataset/ForecastDataforTesting_day' + str(day) + '.csv')\n",
    "        with open('../dataset/x_y_hour.pickle', 'rb') as f:\n",
    "            x_y_hour = pickle.load(f)\n",
    "        df['x_y_hour'] = x_y_hour\n",
    "        df = df.pivot('x_y_hour', 'model', mode)\n",
    "        df['x_y_hour'] = df.index\n",
    "        df['real_index'] = df['x_y_hour'].apply(replace_index)\n",
    "        df = df.sort_values(by=['real_index'])\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        # randomly pick a file to get xid, yid, hour\n",
    "        df_real = pd.read_csv('../dataset/In_situMeasurementforTraining_201802.csv')\n",
    "        df_real_day = df_real[df_real.date_id == 5].reset_index(drop=True)\n",
    "        del df_real\n",
    "        cols = [i for i in range(1, 11)]\n",
    "        cols_for_real = ['xid', 'yid', 'hour']\n",
    "        df = pd.concat([df[cols], df_real_day[cols_for_real]], axis=1)\n",
    "        del df_real_day\n",
    "        features = ['predict_' + str(i) for i in range(1, 11)] + cols_for_real\n",
    "        df.columns = features\n",
    "        df.to_csv('../dataset/' + mode + '_data_day' + str(day)+ '.csv', index=False)\n",
    "        del df\n",
    "        t2 = time.time()\n",
    "        print ('cost {0:.2f}min'.format((t2 - t1) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Outliers processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start day 6 mode wind\n",
      "4152744/4152744: ##################################################\n",
      "cost time 17.59min\n",
      "1252845/4152744 rows are modified\n",
      "start day 6 mode rainfall\n",
      "4152744/4152744: ##################################################\n",
      "cost time 18.47min\n",
      "1855259/4152744 rows are modified\n",
      "start day 7 mode wind\n",
      "4152744/4152744: ##################################################\n",
      "cost time 16.39min\n",
      "1250292/4152744 rows are modified\n",
      "start day 7 mode rainfall\n",
      "4152744/4152744: ##################################################\n",
      "cost time 18.50min\n",
      "2075366/4152744 rows are modified\n",
      "start day 8 mode wind\n",
      "4152744/4152744: ##################################################\n",
      "cost time 16.17min\n",
      "1159772/4152744 rows are modified\n",
      "start day 8 mode rainfall\n",
      "4152744/4152744: ##################################################\n",
      "cost time 15.63min\n",
      "1151703/4152744 rows are modified\n",
      "start day 9 mode wind\n",
      "4152744/4152744: ##################################################\n",
      "cost time 16.44min\n",
      "1282209/4152744 rows are modified\n",
      "start day 9 mode rainfall\n",
      "4152744/4152744: ##################################################\n",
      "cost time 15.53min\n",
      "1154231/4152744 rows are modified\n",
      "start day 10 mode wind\n",
      "4152744/4152744: ##################################################\n",
      "cost time 16.34min\n",
      "1256583/4152744 rows are modified\n",
      "start day 10 mode rainfall\n",
      "4152744/4152744: ##################################################\n",
      "cost time 19.31min\n",
      "1948171/4152744 rows are modified\n"
     ]
    }
   ],
   "source": [
    "for day in range(6, 11, 1):\n",
    "    for mode in ['wind', 'rainfall']:\n",
    "        print ('start day {} mode {}'.format(day, mode))\n",
    "        input_file = '../dataset/' + mode + '_data_day' + str(day) + '.csv'\n",
    "        output_file = '../dataset/' + mode + '_data_day' + str(day) + '_max1.csv'\n",
    "        execute_func(input_file, output_file, mode='max')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
