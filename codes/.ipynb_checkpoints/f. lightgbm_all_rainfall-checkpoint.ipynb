{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for day in range(1, 6):\n",
    "    df_tmp = pd.read_csv('../dataset/rainfall_data_day' + str(day) + '_max1.csv')\n",
    "    df = pd.concat([df, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 70%train+30%validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['hour'] + ['predict_' + str(i) for i in range(1, 11)]\n",
    "X = df[cols].values\n",
    "y = df['real'].values\n",
    "del df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "del X, y\n",
    "\n",
    "feature_name = ['hour', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10']\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 550,\n",
    "    'learning_rate': 0.6,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    \n",
    "}\n",
    "\n",
    "print ('start training')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1500,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[0], \n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day in range(6, 11): \n",
    "    print ('start day {}'.format(day))\n",
    "    df_test = pd.read_csv('../dataset/rainfall_data_day' + str(day) + '_max1.csv')\n",
    "    cols = ['hour'] + ['predict_' + str(i) for i in range(1, 11, 1)]\n",
    "    X_test = df_test[cols].values\n",
    "    y = gbm.predict(X_test)\n",
    "    df_test['predict_final'] = y\n",
    "    df_to_csv = df_test[['xid', 'yid', 'hour', 'predict_final']]\n",
    "    df_to_csv.to_csv('../dataset/rainfall_data_day' + str(day) + '_lgb_all.csv')\n",
    "    del X_test, y, df_to_csv\n",
    "    \n",
    "    for i in range(3, 21):\n",
    "        t1 = time.time()\n",
    "        day_hour = df_test[df_test['hour'] == i]\n",
    "        df_real_day = day_hour.copy()\n",
    "        xid = df_real_day[df_real_day['hour'] == i]['xid']\n",
    "        yid = df_real_day[df_real_day['hour'] == i]['yid'] \n",
    "        rainfall = df_real_day[df_real_day['hour'] == i]['predict_final']\n",
    "        df_test_hour = pd.DataFrame({'xid': list(xid),\n",
    "                      'yid': list(yid),\n",
    "                      'rainfall': list(rainfall)})\n",
    "        pt = df_test_hour.pivot_table(index='xid', columns='yid', values='rainfall', aggfunc=np.sum)\n",
    "        with open('../dataset/day' + str(day) + 'hour'+ str(i) +'.pickle', 'wb') as f:\n",
    "            pickle.dump(pt, f)\n",
    "        t2 = time.time()\n",
    "        print ('cost {}s'.format(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. generate the rain matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day in range(6, 11):\n",
    "    dirpath = '../dataset/'\n",
    "    wind_matrix = -1\n",
    "    for hour in range(3, 21, 1):\n",
    "        filename = 'day'+ str(day) +'hour' + str(hour) + '.pickle'\n",
    "        with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "            matrix = np.array(pickle.load(f, encoding='latin1'))\n",
    "\n",
    "        if isinstance(wind_matrix, int):\n",
    "            wind_matrix = matrix[:, :, np.newaxis]\n",
    "        else:\n",
    "            wind_matrix = np.concatenate([wind_matrix, matrix[:, :, np.newaxis]], axis=2)\n",
    "    dirpath = '../dataset/day' + str(day) \n",
    "    with open(os.path.join(dirpath, 'rain_matrix_lgb.pickle'), 'wb') as f:\n",
    "        pickle.dump(wind_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
