{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV1\n",
    "### trainset: day 2, 3, 4, 5; testset: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_data_day2_max1.csv\n",
      "wind_data_day3_max1.csv\n",
      "wind_data_day4_max1.csv\n",
      "wind_data_day5_max1.csv\n",
      "wind_data_day1_max1.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for filepath in glob.glob('../dataset/wind_data_day[2,3,4,5]_max1.csv'):\n",
    "    filename = os.path.basename(filepath)\n",
    "    print (filename)\n",
    "    df_tmp = pd.read_csv(filepath)\n",
    "    df_train = pd.concat([df_train, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "for filepath in glob.glob('../dataset/wind_data_day[1]_max1.csv'):\n",
    "    filename = os.path.basename(filepath)\n",
    "    print (filename)\n",
    "    df_tmp = pd.read_csv(filepath)\n",
    "    df_test = pd.concat([df_test, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_test.shape\n",
    "\n",
    "df_train['hour'] = df_train['hour'].astype(np.int)\n",
    "df_test['hour'] = df_test['hour'].astype(np.int)\n",
    "\n",
    "X_train = df_train.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_train = df_train['real'].values\n",
    "\n",
    "del df_train\n",
    "\n",
    "X_test = df_test.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_test = df_test['real'].values\n",
    "\n",
    "del df_test\n",
    "\n",
    "# shuffle the array\n",
    "y_train = y_train[:, np.newaxis]\n",
    "training_data = np.hstack( (X_train, y_train) )\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "y_train = training_data[:, -1]\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "del training_data\n",
    "\n",
    "feature_name = ['hour', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10']\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1007: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is [0]\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 12.1397\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 10.0439\n",
      "[3]\tvalid_0's l2: 8.32088\n",
      "[4]\tvalid_0's l2: 6.96414\n",
      "[5]\tvalid_0's l2: 5.85571\n",
      "[6]\tvalid_0's l2: 4.91476\n",
      "[7]\tvalid_0's l2: 4.14499\n",
      "[8]\tvalid_0's l2: 3.58533\n",
      "[9]\tvalid_0's l2: 3.10137\n",
      "[10]\tvalid_0's l2: 2.71014\n",
      "[11]\tvalid_0's l2: 2.37505\n",
      "[12]\tvalid_0's l2: 2.11136\n",
      "[13]\tvalid_0's l2: 1.89628\n",
      "[14]\tvalid_0's l2: 1.73429\n",
      "[15]\tvalid_0's l2: 1.59905\n",
      "[16]\tvalid_0's l2: 1.48275\n",
      "[17]\tvalid_0's l2: 1.3899\n",
      "[18]\tvalid_0's l2: 1.31966\n",
      "[19]\tvalid_0's l2: 1.26005\n",
      "[20]\tvalid_0's l2: 1.21542\n",
      "[21]\tvalid_0's l2: 1.17911\n",
      "[22]\tvalid_0's l2: 1.1492\n",
      "[23]\tvalid_0's l2: 1.12293\n",
      "[24]\tvalid_0's l2: 1.1058\n",
      "[25]\tvalid_0's l2: 1.09156\n",
      "[26]\tvalid_0's l2: 1.07978\n",
      "[27]\tvalid_0's l2: 1.06937\n",
      "[28]\tvalid_0's l2: 1.06143\n",
      "[29]\tvalid_0's l2: 1.05688\n",
      "[30]\tvalid_0's l2: 1.05249\n",
      "[31]\tvalid_0's l2: 1.04904\n",
      "[32]\tvalid_0's l2: 1.0471\n",
      "[33]\tvalid_0's l2: 1.04487\n",
      "[34]\tvalid_0's l2: 1.0427\n",
      "[35]\tvalid_0's l2: 1.04087\n",
      "[36]\tvalid_0's l2: 1.04016\n",
      "[37]\tvalid_0's l2: 1.03951\n",
      "[38]\tvalid_0's l2: 1.03984\n",
      "[39]\tvalid_0's l2: 1.04089\n",
      "[40]\tvalid_0's l2: 1.04142\n",
      "[41]\tvalid_0's l2: 1.04268\n",
      "[42]\tvalid_0's l2: 1.0432\n",
      "[43]\tvalid_0's l2: 1.04383\n",
      "[44]\tvalid_0's l2: 1.04498\n",
      "[45]\tvalid_0's l2: 1.04527\n",
      "[46]\tvalid_0's l2: 1.04562\n",
      "[47]\tvalid_0's l2: 1.04599\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's l2: 1.03951\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 10,\n",
    "    \n",
    "}\n",
    "\n",
    "print ('start training')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1500,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[0], \n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../dataset/lgb_cv1'):\n",
    "    os.makedirs('../dataset/lgb_cv1')\n",
    "with open('../dataset/lgb_cv1/wind_predictor.pickle', 'wb') as f:\n",
    "    pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cv2\n",
    "### trainset: day 1, 3, 4, 5; testset: day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_data_day1_max1.csv\n",
      "wind_data_day3_max1.csv\n",
      "wind_data_day4_max1.csv\n",
      "wind_data_day5_max1.csv\n",
      "wind_data_day2_max1.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[1,3,4,5]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)    \n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_train = pd.concat([df_train, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_train.shape\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[2]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)\n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_test = pd.concat([df_test, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_test.shape\n",
    "\n",
    "df_train['hour'] = df_train['hour'].astype(np.int)\n",
    "df_test['hour'] = df_test['hour'].astype(np.int)\n",
    "\n",
    "X_train = df_train.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_train = df_train['real'].values\n",
    "\n",
    "del df_train\n",
    "\n",
    "X_test = df_test.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_test = df_test['real'].values\n",
    "\n",
    "del df_test\n",
    "\n",
    "# shuffle the array\n",
    "y_train = y_train[:, np.newaxis]\n",
    "training_data = np.hstack( (X_train, y_train) )\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "y_train = training_data[:, -1]\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "del training_data\n",
    "\n",
    "feature_name = ['hour', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10']\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1007: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is [0]\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 28.2546\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 23.2437\n",
      "[3]\tvalid_0's l2: 19.2345\n",
      "[4]\tvalid_0's l2: 16.0195\n",
      "[5]\tvalid_0's l2: 13.3032\n",
      "[6]\tvalid_0's l2: 11.0467\n",
      "[7]\tvalid_0's l2: 9.28649\n",
      "[8]\tvalid_0's l2: 7.84504\n",
      "[9]\tvalid_0's l2: 6.64757\n",
      "[10]\tvalid_0's l2: 5.70004\n",
      "[11]\tvalid_0's l2: 4.96322\n",
      "[12]\tvalid_0's l2: 4.31201\n",
      "[13]\tvalid_0's l2: 3.81335\n",
      "[14]\tvalid_0's l2: 3.41138\n",
      "[15]\tvalid_0's l2: 3.08051\n",
      "[16]\tvalid_0's l2: 2.81195\n",
      "[17]\tvalid_0's l2: 2.61526\n",
      "[18]\tvalid_0's l2: 2.43465\n",
      "[19]\tvalid_0's l2: 2.30907\n",
      "[20]\tvalid_0's l2: 2.18735\n",
      "[21]\tvalid_0's l2: 2.09723\n",
      "[22]\tvalid_0's l2: 2.02595\n",
      "[23]\tvalid_0's l2: 1.97429\n",
      "[24]\tvalid_0's l2: 1.93183\n",
      "[25]\tvalid_0's l2: 1.89965\n",
      "[26]\tvalid_0's l2: 1.87415\n",
      "[27]\tvalid_0's l2: 1.85505\n",
      "[28]\tvalid_0's l2: 1.84546\n",
      "[29]\tvalid_0's l2: 1.83058\n",
      "[30]\tvalid_0's l2: 1.82352\n",
      "[31]\tvalid_0's l2: 1.81519\n",
      "[32]\tvalid_0's l2: 1.8133\n",
      "[33]\tvalid_0's l2: 1.80876\n",
      "[34]\tvalid_0's l2: 1.80561\n",
      "[35]\tvalid_0's l2: 1.80902\n",
      "[36]\tvalid_0's l2: 1.8115\n",
      "[37]\tvalid_0's l2: 1.81144\n",
      "[38]\tvalid_0's l2: 1.81736\n",
      "[39]\tvalid_0's l2: 1.81396\n",
      "[40]\tvalid_0's l2: 1.81693\n",
      "[41]\tvalid_0's l2: 1.81698\n",
      "[42]\tvalid_0's l2: 1.81809\n",
      "[43]\tvalid_0's l2: 1.81968\n",
      "[44]\tvalid_0's l2: 1.82169\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l2: 1.80561\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 10,\n",
    "    \n",
    "}\n",
    "\n",
    "print ('start training')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1500,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[0], \n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../dataset/lgb_cv2'):\n",
    "    os.makedirs('../dataset/lgb_cv2')\n",
    "with open('../dataset/lgb_cv2/wind_predictor.pickle', 'wb') as f:\n",
    "    pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cv3\n",
    "### trainset: day 1, 2, 4, 5; testset: day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_data_day1_max1.csv\n",
      "wind_data_day2_max1.csv\n",
      "wind_data_day4_max1.csv\n",
      "wind_data_day5_max1.csv\n",
      "wind_data_day3_max1.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[1,2,4,5]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)    \n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_train = pd.concat([df_train, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_train.shape\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[3]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)\n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_test = pd.concat([df_test, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_test.shape\n",
    "\n",
    "df_train['hour'] = df_train['hour'].astype(np.int)\n",
    "df_test['hour'] = df_test['hour'].astype(np.int)\n",
    "\n",
    "X_train = df_train.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_train = df_train['real'].values\n",
    "\n",
    "del df_train\n",
    "\n",
    "X_test = df_test.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_test = df_test['real'].values\n",
    "\n",
    "del df_test\n",
    "\n",
    "# shuffle the array\n",
    "y_train = y_train[:, np.newaxis]\n",
    "training_data = np.hstack( (X_train, y_train) )\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "y_train = training_data[:, -1]\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "del training_data\n",
    "\n",
    "feature_name = ['hour', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10']\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1007: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is [0]\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 47.7442\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 39.0454\n",
      "[3]\tvalid_0's l2: 32.0357\n",
      "[4]\tvalid_0's l2: 26.1901\n",
      "[5]\tvalid_0's l2: 21.5721\n",
      "[6]\tvalid_0's l2: 17.6952\n",
      "[7]\tvalid_0's l2: 14.522\n",
      "[8]\tvalid_0's l2: 11.9288\n",
      "[9]\tvalid_0's l2: 9.82064\n",
      "[10]\tvalid_0's l2: 8.05616\n",
      "[11]\tvalid_0's l2: 6.71671\n",
      "[12]\tvalid_0's l2: 5.56501\n",
      "[13]\tvalid_0's l2: 4.64846\n",
      "[14]\tvalid_0's l2: 3.86736\n",
      "[15]\tvalid_0's l2: 3.21628\n",
      "[16]\tvalid_0's l2: 2.69797\n",
      "[17]\tvalid_0's l2: 2.2592\n",
      "[18]\tvalid_0's l2: 1.90795\n",
      "[19]\tvalid_0's l2: 1.61883\n",
      "[20]\tvalid_0's l2: 1.37434\n",
      "[21]\tvalid_0's l2: 1.17716\n",
      "[22]\tvalid_0's l2: 1.01933\n",
      "[23]\tvalid_0's l2: 0.887141\n",
      "[24]\tvalid_0's l2: 0.780027\n",
      "[25]\tvalid_0's l2: 0.687335\n",
      "[26]\tvalid_0's l2: 0.614321\n",
      "[27]\tvalid_0's l2: 0.55591\n",
      "[28]\tvalid_0's l2: 0.515893\n",
      "[29]\tvalid_0's l2: 0.47349\n",
      "[30]\tvalid_0's l2: 0.44032\n",
      "[31]\tvalid_0's l2: 0.411673\n",
      "[32]\tvalid_0's l2: 0.389363\n",
      "[33]\tvalid_0's l2: 0.373081\n",
      "[34]\tvalid_0's l2: 0.361123\n",
      "[35]\tvalid_0's l2: 0.347965\n",
      "[36]\tvalid_0's l2: 0.341869\n",
      "[37]\tvalid_0's l2: 0.333939\n",
      "[38]\tvalid_0's l2: 0.326427\n",
      "[39]\tvalid_0's l2: 0.321111\n",
      "[40]\tvalid_0's l2: 0.316835\n",
      "[41]\tvalid_0's l2: 0.314357\n",
      "[42]\tvalid_0's l2: 0.310289\n",
      "[43]\tvalid_0's l2: 0.307936\n",
      "[44]\tvalid_0's l2: 0.305851\n",
      "[45]\tvalid_0's l2: 0.304501\n",
      "[46]\tvalid_0's l2: 0.302843\n",
      "[47]\tvalid_0's l2: 0.30155\n",
      "[48]\tvalid_0's l2: 0.300613\n",
      "[49]\tvalid_0's l2: 0.299583\n",
      "[50]\tvalid_0's l2: 0.298663\n",
      "[51]\tvalid_0's l2: 0.297982\n",
      "[52]\tvalid_0's l2: 0.29772\n",
      "[53]\tvalid_0's l2: 0.29761\n",
      "[54]\tvalid_0's l2: 0.297538\n",
      "[55]\tvalid_0's l2: 0.29735\n",
      "[56]\tvalid_0's l2: 0.297203\n",
      "[57]\tvalid_0's l2: 0.297151\n",
      "[58]\tvalid_0's l2: 0.297235\n",
      "[59]\tvalid_0's l2: 0.29738\n",
      "[60]\tvalid_0's l2: 0.297573\n",
      "[61]\tvalid_0's l2: 0.297651\n",
      "[62]\tvalid_0's l2: 0.297729\n",
      "[63]\tvalid_0's l2: 0.297831\n",
      "[64]\tvalid_0's l2: 0.298115\n",
      "[65]\tvalid_0's l2: 0.298104\n",
      "[66]\tvalid_0's l2: 0.298377\n",
      "[67]\tvalid_0's l2: 0.298723\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 0.297151\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 10,\n",
    "    \n",
    "}\n",
    "\n",
    "print ('start training')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1500,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[0], \n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../dataset/lgb_cv3'):\n",
    "    os.makedirs('../dataset/lgb_cv3')\n",
    "with open('../dataset/lgb_cv3/wind_predictor.pickle', 'wb') as f:\n",
    "    pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cv4\n",
    "### trainset: day 1, 2, 3, 5; testset: day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_data_day1_max1.csv\n",
      "wind_data_day2_max1.csv\n",
      "wind_data_day3_max1.csv\n",
      "wind_data_day5_max1.csv\n",
      "wind_data_day4_max1.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[1,2,3,5]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)    \n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_train = pd.concat([df_train, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_train.shape\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[4]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)\n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_test = pd.concat([df_test, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_test.shape\n",
    "\n",
    "df_train['hour'] = df_train['hour'].astype(np.int)\n",
    "df_test['hour'] = df_test['hour'].astype(np.int)\n",
    "\n",
    "X_train = df_train.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_train = df_train['real'].values\n",
    "\n",
    "del df_train\n",
    "\n",
    "X_test = df_test.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_test = df_test['real'].values\n",
    "\n",
    "del df_test\n",
    "\n",
    "# shuffle the array\n",
    "y_train = y_train[:, np.newaxis]\n",
    "training_data = np.hstack( (X_train, y_train) )\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "y_train = training_data[:, -1]\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "del training_data\n",
    "\n",
    "feature_name = ['hour', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10']\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1007: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is [0]\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 20.1337\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 16.9946\n",
      "[3]\tvalid_0's l2: 14.1676\n",
      "[4]\tvalid_0's l2: 12.014\n",
      "[5]\tvalid_0's l2: 10.1438\n",
      "[6]\tvalid_0's l2: 8.77338\n",
      "[7]\tvalid_0's l2: 7.53816\n",
      "[8]\tvalid_0's l2: 6.54026\n",
      "[9]\tvalid_0's l2: 5.67512\n",
      "[10]\tvalid_0's l2: 5.03971\n",
      "[11]\tvalid_0's l2: 4.50038\n",
      "[12]\tvalid_0's l2: 4.04549\n",
      "[13]\tvalid_0's l2: 3.68435\n",
      "[14]\tvalid_0's l2: 3.36407\n",
      "[15]\tvalid_0's l2: 3.09098\n",
      "[16]\tvalid_0's l2: 2.88858\n",
      "[17]\tvalid_0's l2: 2.72329\n",
      "[18]\tvalid_0's l2: 2.57151\n",
      "[19]\tvalid_0's l2: 2.44808\n",
      "[20]\tvalid_0's l2: 2.3473\n",
      "[21]\tvalid_0's l2: 2.25802\n",
      "[22]\tvalid_0's l2: 2.18235\n",
      "[23]\tvalid_0's l2: 2.12265\n",
      "[24]\tvalid_0's l2: 2.0728\n",
      "[25]\tvalid_0's l2: 2.02942\n",
      "[26]\tvalid_0's l2: 1.99184\n",
      "[27]\tvalid_0's l2: 1.96402\n",
      "[28]\tvalid_0's l2: 1.93617\n",
      "[29]\tvalid_0's l2: 1.91415\n",
      "[30]\tvalid_0's l2: 1.89718\n",
      "[31]\tvalid_0's l2: 1.88298\n",
      "[32]\tvalid_0's l2: 1.86835\n",
      "[33]\tvalid_0's l2: 1.85352\n",
      "[34]\tvalid_0's l2: 1.84178\n",
      "[35]\tvalid_0's l2: 1.8309\n",
      "[36]\tvalid_0's l2: 1.82293\n",
      "[37]\tvalid_0's l2: 1.817\n",
      "[38]\tvalid_0's l2: 1.8138\n",
      "[39]\tvalid_0's l2: 1.80693\n",
      "[40]\tvalid_0's l2: 1.80098\n",
      "[41]\tvalid_0's l2: 1.7986\n",
      "[42]\tvalid_0's l2: 1.79534\n",
      "[43]\tvalid_0's l2: 1.79393\n",
      "[44]\tvalid_0's l2: 1.79029\n",
      "[45]\tvalid_0's l2: 1.78748\n",
      "[46]\tvalid_0's l2: 1.78486\n",
      "[47]\tvalid_0's l2: 1.78517\n",
      "[48]\tvalid_0's l2: 1.78525\n",
      "[49]\tvalid_0's l2: 1.78827\n",
      "[50]\tvalid_0's l2: 1.78791\n",
      "[51]\tvalid_0's l2: 1.78915\n",
      "[52]\tvalid_0's l2: 1.79135\n",
      "[53]\tvalid_0's l2: 1.79129\n",
      "[54]\tvalid_0's l2: 1.79034\n",
      "[55]\tvalid_0's l2: 1.7887\n",
      "[56]\tvalid_0's l2: 1.78771\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's l2: 1.78486\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 150,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 10,\n",
    "    \n",
    "}\n",
    "\n",
    "print ('start training')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1500,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[0], \n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../dataset/lgb_cv4'):\n",
    "    os.makedirs('../dataset/lgb_cv4')\n",
    "with open('../dataset/lgb_cv4/wind_predictor.pickle', 'wb') as f:\n",
    "    pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cv5\n",
    "### trainset: day 1, 2, 3, 4; testset: day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_data_day1_max1.csv\n",
      "wind_data_day2_max1.csv\n",
      "wind_data_day3_max1.csv\n",
      "wind_data_day4_max1.csv\n",
      "wind_data_day5_max1.csv\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[1,2,3,4]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)    \n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_train = pd.concat([df_train, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_train.shape\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "for file in glob.glob('../dataset/wind_data_day[5]_max1.csv'):\n",
    "    filename = os.path.basename(file)\n",
    "    print (filename)\n",
    "    df_tmp = pd.read_csv(file)\n",
    "    df_test = pd.concat([df_test, df_tmp], axis=0)\n",
    "    del df_tmp\n",
    "df_test.shape\n",
    "\n",
    "df_train['hour'] = df_train['hour'].astype(np.int)\n",
    "df_test['hour'] = df_test['hour'].astype(np.int)\n",
    "\n",
    "X_train = df_train.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_train = df_train['real'].values\n",
    "\n",
    "del df_train\n",
    "\n",
    "X_test = df_test.drop(['real', 'xid', 'yid'], axis=1).values\n",
    "y_test = df_test['real'].values\n",
    "\n",
    "del df_test\n",
    "\n",
    "# shuffle the array\n",
    "y_train = y_train[:, np.newaxis]\n",
    "training_data = np.hstack( (X_train, y_train) )\n",
    "np.random.shuffle(training_data)\n",
    "\n",
    "X_train = training_data[:, :-1]\n",
    "y_train = training_data[:, -1]\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "del training_data\n",
    "\n",
    "feature_name = ['hour', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9', 'p10']\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1007: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is [0]\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 26.6\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 21.7759\n",
      "[3]\tvalid_0's l2: 17.8829\n",
      "[4]\tvalid_0's l2: 14.6802\n",
      "[5]\tvalid_0's l2: 12.0758\n",
      "[6]\tvalid_0's l2: 10.0436\n",
      "[7]\tvalid_0's l2: 8.32718\n",
      "[8]\tvalid_0's l2: 6.91574\n",
      "[9]\tvalid_0's l2: 5.80176\n",
      "[10]\tvalid_0's l2: 4.85734\n",
      "[11]\tvalid_0's l2: 4.09453\n",
      "[12]\tvalid_0's l2: 3.48908\n",
      "[13]\tvalid_0's l2: 2.99919\n",
      "[14]\tvalid_0's l2: 2.56847\n",
      "[15]\tvalid_0's l2: 2.22827\n",
      "[16]\tvalid_0's l2: 1.95622\n",
      "[17]\tvalid_0's l2: 1.72378\n",
      "[18]\tvalid_0's l2: 1.53499\n",
      "[19]\tvalid_0's l2: 1.38607\n",
      "[20]\tvalid_0's l2: 1.25554\n",
      "[21]\tvalid_0's l2: 1.14684\n",
      "[22]\tvalid_0's l2: 1.05556\n",
      "[23]\tvalid_0's l2: 0.981741\n",
      "[24]\tvalid_0's l2: 0.919629\n",
      "[25]\tvalid_0's l2: 0.867578\n",
      "[26]\tvalid_0's l2: 0.826864\n",
      "[27]\tvalid_0's l2: 0.791424\n",
      "[28]\tvalid_0's l2: 0.763044\n",
      "[29]\tvalid_0's l2: 0.738866\n",
      "[30]\tvalid_0's l2: 0.718978\n",
      "[31]\tvalid_0's l2: 0.702244\n",
      "[32]\tvalid_0's l2: 0.688101\n",
      "[33]\tvalid_0's l2: 0.676299\n",
      "[34]\tvalid_0's l2: 0.666766\n",
      "[35]\tvalid_0's l2: 0.659601\n",
      "[36]\tvalid_0's l2: 0.652869\n",
      "[37]\tvalid_0's l2: 0.647059\n",
      "[38]\tvalid_0's l2: 0.641836\n",
      "[39]\tvalid_0's l2: 0.63714\n",
      "[40]\tvalid_0's l2: 0.633598\n",
      "[41]\tvalid_0's l2: 0.630508\n",
      "[42]\tvalid_0's l2: 0.627704\n",
      "[43]\tvalid_0's l2: 0.625014\n",
      "[44]\tvalid_0's l2: 0.622798\n",
      "[45]\tvalid_0's l2: 0.621102\n",
      "[46]\tvalid_0's l2: 0.618972\n",
      "[47]\tvalid_0's l2: 0.617415\n",
      "[48]\tvalid_0's l2: 0.616055\n",
      "[49]\tvalid_0's l2: 0.615109\n",
      "[50]\tvalid_0's l2: 0.614584\n",
      "[51]\tvalid_0's l2: 0.61379\n",
      "[52]\tvalid_0's l2: 0.612886\n",
      "[53]\tvalid_0's l2: 0.612079\n",
      "[54]\tvalid_0's l2: 0.611595\n",
      "[55]\tvalid_0's l2: 0.611038\n",
      "[56]\tvalid_0's l2: 0.61043\n",
      "[57]\tvalid_0's l2: 0.6096\n",
      "[58]\tvalid_0's l2: 0.609584\n",
      "[59]\tvalid_0's l2: 0.609312\n",
      "[60]\tvalid_0's l2: 0.60908\n",
      "[61]\tvalid_0's l2: 0.609006\n",
      "[62]\tvalid_0's l2: 0.608613\n",
      "[63]\tvalid_0's l2: 0.608198\n",
      "[64]\tvalid_0's l2: 0.608242\n",
      "[65]\tvalid_0's l2: 0.608349\n",
      "[66]\tvalid_0's l2: 0.608891\n",
      "[67]\tvalid_0's l2: 0.608663\n",
      "[68]\tvalid_0's l2: 0.608816\n",
      "[69]\tvalid_0's l2: 0.608649\n",
      "[70]\tvalid_0's l2: 0.608472\n",
      "[71]\tvalid_0's l2: 0.608842\n",
      "[72]\tvalid_0's l2: 0.608766\n",
      "[73]\tvalid_0's l2: 0.608536\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l2: 0.608198\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'},\n",
    "    'num_leaves': 200,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.3,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 10,\n",
    "    \n",
    "}\n",
    "\n",
    "print ('start training')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1500,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[0], \n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('../dataset/lgb_cv5'):\n",
    "    os.makedirs('../dataset/lgb_cv5')\n",
    "with open('../dataset/lgb_cv5/wind_predictor.pickle', 'wb') as f:\n",
    "    pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start day 6\n",
      "cost 0.5805401802062988s\n",
      "cost 0.4301445484161377s\n",
      "cost 0.42816662788391113s\n",
      "cost 0.4331519603729248s\n",
      "cost 0.5093553066253662s\n",
      "cost 0.43515610694885254s\n",
      "cost 0.42713356018066406s\n",
      "cost 0.5645020008087158s\n",
      "cost 0.43214869499206543s\n",
      "cost 0.4331512451171875s\n",
      "cost 0.4301438331604004s\n",
      "cost 0.42415857315063477s\n",
      "cost 0.4301128387451172s\n",
      "cost 0.4341566562652588s\n",
      "cost 0.43114566802978516s\n",
      "cost 0.4291422367095947s\n",
      "cost 0.4291400909423828s\n",
      "cost 0.4371633529663086s\n",
      "start day 7\n",
      "cost 0.4331545829772949s\n",
      "cost 0.45921826362609863s\n",
      "cost 0.5183651447296143s\n",
      "cost 0.44217538833618164s\n",
      "cost 0.5314478874206543s\n",
      "cost 0.47225522994995117s\n",
      "cost 0.719916820526123s\n",
      "cost 0.4882979393005371s\n",
      "cost 0.5855557918548584s\n",
      "cost 0.5634996891021729s\n",
      "cost 0.5274014472961426s\n",
      "cost 0.4271361827850342s\n",
      "cost 0.4431779384613037s\n",
      "cost 0.4501969814300537s\n",
      "cost 0.4582178592681885s\n",
      "cost 0.44618678092956543s\n",
      "cost 0.8312108516693115s\n",
      "cost 0.7299158573150635s\n",
      "start day 8\n",
      "cost 0.44217610359191895s\n",
      "cost 0.4361598491668701s\n",
      "cost 0.4271361827850342s\n",
      "cost 0.439197301864624s\n",
      "cost 0.42510247230529785s\n",
      "cost 0.42412829399108887s\n",
      "cost 0.45621514320373535s\n",
      "cost 0.42412447929382324s\n",
      "cost 0.5253973007202148s\n",
      "cost 0.542442798614502s\n",
      "cost 0.4301424026489258s\n",
      "cost 0.4271421432495117s\n",
      "cost 0.4281320571899414s\n",
      "cost 0.4501969814300537s\n",
      "cost 0.4411735534667969s\n",
      "cost 0.43115711212158203s\n",
      "cost 0.44917821884155273s\n",
      "cost 0.42415714263916016s\n",
      "start day 9\n",
      "cost 0.46624207496643066s\n",
      "cost 0.44618916511535645s\n",
      "cost 0.4642369747161865s\n",
      "cost 0.439164400100708s\n",
      "cost 0.46222877502441406s\n",
      "cost 0.4532043933868408s\n",
      "cost 0.4331517219543457s\n",
      "cost 0.4401710033416748s\n",
      "cost 0.43515658378601074s\n",
      "cost 0.478271484375s\n",
      "cost 0.4511988162994385s\n",
      "cost 0.5123634338378906s\n",
      "cost 0.4261324405670166s\n",
      "cost 0.451200008392334s\n",
      "cost 0.423123836517334s\n",
      "cost 0.4672420024871826s\n",
      "cost 0.4501953125s\n",
      "cost 0.43415307998657227s\n",
      "start day 10\n",
      "cost 0.44117283821105957s\n",
      "cost 0.42412781715393066s\n",
      "cost 0.4371628761291504s\n",
      "cost 0.4923081398010254s\n",
      "cost 0.4291694164276123s\n",
      "cost 0.43114399909973145s\n",
      "cost 0.42512941360473633s\n",
      "cost 0.4291689395904541s\n",
      "cost 0.42412877082824707s\n",
      "cost 0.43816399574279785s\n",
      "cost 0.4431788921356201s\n",
      "cost 0.432175874710083s\n",
      "cost 0.55745530128479s\n",
      "cost 0.45921993255615234s\n",
      "cost 0.47727060317993164s\n",
      "cost 0.44217562675476074s\n",
      "cost 0.43114566802978516s\n",
      "cost 0.42412805557250977s\n",
      "start day 6\n",
      "cost 0.4341545104980469s\n",
      "cost 0.42111945152282715s\n",
      "cost 1.374654769897461s\n",
      "cost 0.4471883773803711s\n",
      "cost 0.43214869499206543s\n",
      "cost 0.4822854995727539s\n",
      "cost 0.41911983489990234s\n",
      "cost 0.4230763912200928s\n",
      "cost 0.4261329174041748s\n",
      "cost 0.42513132095336914s\n",
      "cost 0.41811227798461914s\n",
      "cost 0.4221212863922119s\n",
      "cost 0.43916869163513184s\n",
      "cost 0.42111897468566895s\n",
      "cost 0.42713499069213867s\n",
      "cost 0.42412662506103516s\n",
      "cost 0.4291419982910156s\n",
      "cost 0.45521020889282227s\n",
      "start day 7\n",
      "cost 0.434154748916626s\n",
      "cost 0.4191157817840576s\n",
      "cost 0.42111730575561523s\n",
      "cost 0.4261329174041748s\n",
      "cost 0.4401719570159912s\n",
      "cost 0.4191145896911621s\n",
      "cost 0.4191122055053711s\n",
      "cost 0.4291410446166992s\n",
      "cost 0.4231255054473877s\n",
      "cost 0.42513036727905273s\n",
      "cost 0.460223913192749s\n",
      "cost 0.43819403648376465s\n",
      "cost 0.42111921310424805s\n",
      "cost 0.42112040519714355s\n",
      "cost 0.4261324405670166s\n",
      "cost 0.41410231590270996s\n",
      "cost 0.44622063636779785s\n",
      "cost 0.4251234531402588s\n",
      "start day 8\n",
      "cost 0.43114757537841797s\n",
      "cost 0.43017148971557617s\n",
      "cost 0.42011523246765137s\n",
      "cost 0.4201195240020752s\n",
      "cost 0.4251289367675781s\n",
      "cost 0.48729395866394043s\n",
      "cost 0.43114662170410156s\n",
      "cost 0.42713403701782227s\n",
      "cost 0.42513108253479004s\n",
      "cost 0.44919419288635254s\n",
      "cost 0.4221222400665283s\n",
      "cost 0.42813968658447266s\n",
      "cost 0.4231243133544922s\n",
      "cost 0.4231240749359131s\n",
      "cost 0.4311504364013672s\n",
      "cost 0.7259316444396973s\n",
      "cost 0.725928544998169s\n",
      "cost 0.4371514320373535s\n",
      "start day 9\n",
      "cost 0.43616247177124023s\n",
      "cost 0.41613221168518066s\n",
      "cost 0.4200887680053711s\n",
      "cost 0.41811442375183105s\n",
      "cost 0.45220279693603516s\n",
      "cost 0.4411733150482178s\n",
      "cost 0.5083520412445068s\n",
      "cost 0.4722602367401123s\n",
      "cost 0.4531998634338379s\n",
      "cost 0.47927331924438477s\n",
      "cost 0.4301440715789795s\n",
      "cost 0.4462141990661621s\n",
      "cost 0.44819211959838867s\n",
      "cost 0.461228609085083s\n",
      "cost 0.4532334804534912s\n",
      "cost 0.4612259864807129s\n",
      "cost 0.45220303535461426s\n",
      "cost 0.45621252059936523s\n",
      "start day 10\n",
      "cost 0.7560088634490967s\n",
      "cost 0.8041379451751709s\n",
      "cost 0.550469160079956s\n",
      "cost 0.485321044921875s\n",
      "cost 0.4822819232940674s\n",
      "cost 0.44117259979248047s\n",
      "cost 0.5645034313201904s\n",
      "cost 0.7700459957122803s\n",
      "cost 0.8241901397705078s\n",
      "cost 0.692847728729248s\n",
      "cost 1.2874224185943604s\n",
      "cost 0.8883621692657471s\n",
      "cost 0.6577484607696533s\n",
      "cost 0.7177095413208008s\n",
      "cost 0.7702906131744385s\n",
      "cost 0.8547747135162354s\n",
      "cost 0.6898288726806641s\n",
      "cost 1.2031912803649902s\n",
      "start day 6\n",
      "cost 0.46624302864074707s\n",
      "cost 0.4923100471496582s\n",
      "cost 0.4321608543395996s\n",
      "cost 0.4762554168701172s\n",
      "cost 0.450197696685791s\n",
      "cost 0.4431779384613037s\n",
      "cost 0.49030327796936035s\n",
      "cost 0.5073487758636475s\n",
      "cost 0.44719457626342773s\n",
      "cost 0.44217586517333984s\n",
      "cost 0.43816661834716797s\n",
      "cost 0.4512288570404053s\n",
      "cost 0.5133635997772217s\n",
      "cost 0.4341566562652588s\n",
      "cost 0.4682431221008301s\n",
      "cost 0.46022486686706543s\n",
      "cost 0.46724486351013184s\n",
      "cost 0.445209264755249s\n",
      "start day 7\n",
      "cost 0.5274233818054199s\n",
      "cost 0.47123122215270996s\n",
      "cost 0.4752655029296875s\n",
      "cost 0.45220112800598145s\n",
      "cost 0.47325849533081055s\n",
      "cost 0.6911287307739258s\n",
      "cost 0.5128674507141113s\n",
      "cost 0.47024989128112793s\n",
      "cost 0.46273159980773926s\n",
      "cost 0.4847872257232666s\n",
      "cost 0.5309231281280518s\n",
      "cost 0.44919586181640625s\n",
      "cost 0.4431793689727783s\n",
      "cost 0.47626399993896484s\n",
      "cost 0.4481925964355469s\n",
      "cost 0.4401702880859375s\n",
      "cost 0.44518303871154785s\n",
      "cost 0.43816518783569336s\n",
      "start day 8\n",
      "cost 0.4582209587097168s\n",
      "cost 0.45220136642456055s\n",
      "cost 0.44518375396728516s\n",
      "cost 0.4542064666748047s\n",
      "cost 0.44521164894104004s\n",
      "cost 0.4421505928039551s\n",
      "cost 0.5073490142822266s\n",
      "cost 0.514366626739502s\n",
      "cost 0.44220542907714844s\n",
      "cost 0.4411752223968506s\n",
      "cost 0.4441814422607422s\n",
      "cost 0.45423364639282227s\n",
      "cost 0.4361839294433594s\n",
      "cost 0.44619011878967285s\n",
      "cost 0.4511728286743164s\n",
      "cost 0.4822816848754883s\n",
      "cost 0.5464532375335693s\n",
      "cost 0.5424425601959229s\n",
      "start day 9\n",
      "cost 0.4572174549102783s\n",
      "cost 0.4612252712249756s\n",
      "cost 0.453204870223999s\n",
      "cost 0.4582183361053467s\n",
      "cost 0.4582188129425049s\n",
      "cost 0.45621490478515625s\n",
      "cost 0.5203840732574463s\n",
      "cost 0.6126558780670166s\n",
      "cost 0.45718908309936523s\n",
      "cost 0.44819045066833496s\n",
      "cost 0.45621299743652344s\n",
      "cost 0.48428845405578613s\n",
      "cost 0.4712536334991455s\n",
      "cost 0.45423412322998047s\n",
      "cost 0.49428820610046387s\n",
      "cost 0.47626614570617676s\n",
      "cost 0.46924805641174316s\n",
      "cost 0.44819021224975586s\n",
      "start day 10\n",
      "cost 0.4933135509490967s\n",
      "cost 0.5163757801055908s\n",
      "cost 0.6487231254577637s\n",
      "cost 0.4632303714752197s\n",
      "cost 0.581545352935791s\n",
      "cost 0.5173735618591309s\n",
      "cost 0.550464391708374s\n",
      "cost 0.7720527648925781s\n",
      "cost 0.5163722038269043s\n",
      "cost 0.45220422744750977s\n",
      "cost 0.46523523330688477s\n",
      "cost 0.4742612838745117s\n",
      "cost 0.48328447341918945s\n",
      "cost 0.4652364253997803s\n",
      "cost 0.4722592830657959s\n",
      "cost 0.46225762367248535s\n",
      "cost 0.4782705307006836s\n",
      "cost 0.6397032737731934s\n",
      "start day 6\n",
      "cost 0.4913063049316406s\n",
      "cost 0.45320796966552734s\n",
      "cost 0.4642324447631836s\n",
      "cost 0.4822814464569092s\n",
      "cost 0.5103576183319092s\n",
      "cost 0.6657495498657227s\n",
      "cost 0.4652383327484131s\n",
      "cost 0.46927905082702637s\n",
      "cost 0.4712531566619873s\n",
      "cost 0.46627092361450195s\n",
      "cost 0.6296429634094238s\n",
      "cost 0.5354228019714355s\n",
      "cost 0.5464527606964111s\n",
      "cost 0.4762685298919678s\n",
      "cost 0.4562385082244873s\n",
      "cost 0.6045799255371094s\n",
      "cost 0.48428893089294434s\n",
      "cost 0.44420766830444336s\n",
      "start day 7\n",
      "cost 0.4682466983795166s\n",
      "cost 0.4882962703704834s\n",
      "cost 0.48027896881103516s\n",
      "cost 0.446185827255249s\n",
      "cost 0.45521068572998047s\n",
      "cost 0.447188138961792s\n",
      "cost 0.47827982902526855s\n",
      "cost 0.45018982887268066s\n",
      "cost 0.5294084548950195s\n",
      "cost 0.5274026393890381s\n",
      "cost 0.4682450294494629s\n",
      "cost 0.44217705726623535s\n",
      "cost 0.44521093368530273s\n",
      "cost 0.48024845123291016s\n",
      "cost 0.4542069435119629s\n",
      "cost 0.44217801094055176s\n",
      "cost 0.44919443130493164s\n",
      "cost 0.4612250328063965s\n",
      "start day 8\n",
      "cost 0.5604939460754395s\n",
      "cost 0.5243923664093018s\n",
      "cost 0.5384306907653809s\n",
      "cost 0.6537392139434814s\n",
      "cost 0.46222996711730957s\n",
      "cost 0.4471886157989502s\n",
      "cost 0.4511983394622803s\n",
      "cost 0.463238000869751s\n",
      "cost 0.506338357925415s\n",
      "cost 0.5113613605499268s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 0.4742605686187744s\n",
      "cost 0.4371626377105713s\n",
      "cost 0.4572439193725586s\n",
      "cost 0.43816494941711426s\n",
      "cost 0.6928412914276123s\n",
      "cost 0.5304107666015625s\n",
      "cost 0.4882967472076416s\n",
      "cost 0.4822838306427002s\n",
      "start day 9\n",
      "cost 0.5984914302825928s\n",
      "cost 0.6492259502410889s\n",
      "cost 0.5384387969970703s\n",
      "cost 0.5433762073516846s\n",
      "cost 0.5228898525238037s\n",
      "cost 0.5239062309265137s\n",
      "cost 0.522878885269165s\n",
      "cost 0.5325517654418945s\n",
      "cost 0.5380122661590576s\n",
      "cost 0.5285389423370361s\n",
      "cost 0.5509638786315918s\n",
      "cost 0.6618061065673828s\n",
      "cost 0.5386340618133545s\n",
      "cost 0.531268835067749s\n",
      "cost 0.536513090133667s\n",
      "cost 0.5345287322998047s\n",
      "cost 0.5183801651000977s\n",
      "cost 0.5178961753845215s\n",
      "start day 10\n",
      "cost 0.6378202438354492s\n",
      "cost 0.6507303714752197s\n",
      "cost 0.5178749561309814s\n",
      "cost 0.531909704208374s\n",
      "cost 0.5400240421295166s\n",
      "cost 0.5078494548797607s\n",
      "cost 0.5294129848480225s\n",
      "cost 0.5460026264190674s\n",
      "cost 0.5401005744934082s\n",
      "cost 0.5183815956115723s\n",
      "cost 0.601600170135498s\n",
      "cost 0.7085142135620117s\n",
      "cost 0.5870611667633057s\n",
      "cost 0.8933744430541992s\n",
      "cost 0.6298089027404785s\n",
      "cost 0.5258965492248535s\n",
      "cost 0.5471959114074707s\n",
      "cost 0.5449492931365967s\n",
      "start day 6\n",
      "cost 0.5730240345001221s\n",
      "cost 0.5404379367828369s\n",
      "cost 0.588446855545044s\n",
      "cost 0.5735242366790771s\n",
      "cost 0.5173749923706055s\n",
      "cost 0.5362744331359863s\n",
      "cost 0.5299079418182373s\n",
      "cost 0.527402400970459s\n",
      "cost 0.5218887329101562s\n",
      "cost 0.5377843379974365s\n",
      "cost 0.5650022029876709s\n",
      "cost 0.5203847885131836s\n",
      "cost 0.5880653858184814s\n",
      "cost 0.5591094493865967s\n",
      "cost 0.5335159301757812s\n",
      "cost 0.5995955467224121s\n",
      "cost 1.0350475311279297s\n",
      "cost 0.578528881072998s\n",
      "start day 7\n",
      "cost 0.5870623588562012s\n",
      "cost 0.5384304523468018s\n",
      "cost 0.6348304748535156s\n",
      "cost 0.5213866233825684s\n",
      "cost 0.5113589763641357s\n",
      "cost 0.5304055213928223s\n",
      "cost 0.5248956680297852s\n",
      "cost 0.6371936798095703s\n",
      "cost 0.6134953498840332s\n",
      "cost 0.5449490547180176s\n",
      "cost 0.5464560985565186s\n",
      "cost 0.5594873428344727s\n",
      "cost 0.6148746013641357s\n",
      "cost 0.5203819274902344s\n",
      "cost 0.515376091003418s\n",
      "cost 0.5160698890686035s\n",
      "cost 0.5334169864654541s\n",
      "cost 0.5183796882629395s\n",
      "start day 8\n",
      "cost 0.5441703796386719s\n",
      "cost 0.531914234161377s\n",
      "cost 0.511859655380249s\n",
      "cost 0.576030969619751s\n",
      "cost 0.5454490184783936s\n",
      "cost 0.5088529586791992s\n",
      "cost 0.5710170269012451s\n",
      "cost 0.5859255790710449s\n",
      "cost 0.51888108253479s\n",
      "cost 0.5163707733154297s\n",
      "cost 0.5384945869445801s\n",
      "cost 0.5058627128601074s\n",
      "cost 0.5258994102478027s\n",
      "cost 0.5574827194213867s\n",
      "cost 0.5389339923858643s\n",
      "cost 0.5098512172698975s\n",
      "cost 0.5650026798248291s\n",
      "cost 0.6013178825378418s\n",
      "start day 9\n",
      "cost 0.5429434776306152s\n",
      "cost 0.5396645069122314s\n",
      "cost 0.6211497783660889s\n",
      "cost 0.5093533992767334s\n",
      "cost 0.5509653091430664s\n",
      "cost 0.5173773765563965s\n",
      "cost 0.5780344009399414s\n",
      "cost 0.521888256072998s\n",
      "cost 0.557941198348999s\n",
      "cost 0.5243945121765137s\n",
      "cost 0.5198817253112793s\n",
      "cost 0.5980913639068604s\n",
      "cost 0.5800421237945557s\n",
      "cost 0.5198836326599121s\n",
      "cost 0.5123624801635742s\n",
      "cost 0.5334141254425049s\n",
      "cost 0.5730557441711426s\n",
      "cost 0.5123624801635742s\n",
      "start day 10\n",
      "cost 0.611332893371582s\n",
      "cost 0.5494608879089355s\n",
      "cost 0.514366626739502s\n",
      "cost 0.519883394241333s\n",
      "cost 0.5204737186431885s\n",
      "cost 0.6939001083374023s\n",
      "cost 0.5203993320465088s\n",
      "cost 0.5263986587524414s\n",
      "cost 0.5329179763793945s\n",
      "cost 0.5609908103942871s\n",
      "cost 0.5349218845367432s\n",
      "cost 0.5269021987915039s\n",
      "cost 0.529710054397583s\n",
      "cost 0.5324139595031738s\n",
      "cost 0.5449490547180176s\n",
      "cost 0.6553750038146973s\n",
      "cost 0.5153687000274658s\n",
      "cost 0.5319147109985352s\n"
     ]
    }
   ],
   "source": [
    "for vs in range(1, 6):\n",
    "\n",
    "    with open('../dataset/lgb_cv' + str(vs) + '/wind_predictor.pickle', 'rb') as f:\n",
    "            gbm = pickle.load(f)\n",
    "\n",
    "    for day in range(6, 11, 1): \n",
    "        print ('start day {}'.format(day))\n",
    "        df_test = pd.read_csv('../dataset/wind_data_day' + str(day) + '_max1.csv')\n",
    "        cols = ['hour'] + ['predict_' + str(model) for model in range(1, 11, 1)]\n",
    "        X_test = df_test[cols].values\n",
    "        y = gbm.predict(X_test)\n",
    "        df_test['predict_final'] = y\n",
    "        df_to_csv = df_test[['xid', 'yid', 'hour', 'predict_final']]\n",
    "        df_to_csv.to_csv('../dataset/lgb_cv' + str(vs) + '/wind_lightgbm_day' + str(day) + '.csv')\n",
    "        del X_test, y, df_to_csv\n",
    "\n",
    "        for i in range(3, 21):\n",
    "            t1 = time.time()\n",
    "            day_hour = df_test[df_test['hour'] == i]\n",
    "            df_real_day = day_hour.copy()\n",
    "            xid = df_real_day[df_real_day['hour'] == i]['xid']\n",
    "            yid = df_real_day[df_real_day['hour'] == i]['yid'] \n",
    "            wind = df_real_day[df_real_day['hour'] == i]['predict_final']\n",
    "            df_test_hour = pd.DataFrame({'xid': list(xid),\n",
    "                          'yid': list(yid),\n",
    "                          'wind': list(wind)})\n",
    "            pt = df_test_hour.pivot_table(index='xid', columns='yid', values='wind', aggfunc=np.sum)\n",
    "            with open('../dataset/lgb_cv' + str(vs) + '/day' + str(day) + 'hour'+ str(i) +'.pickle', 'wb') as f:\n",
    "                pickle.dump(pt, f)\n",
    "            t2 = time.time()\n",
    "            print ('cost {}s'.format(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for vs in range(1, 6, 1):\n",
    "    for day in range(6, 11, 1):\n",
    "        dirpath ='../dataset/lgb_cv' + str(vs)\n",
    "        wind_matrix = -1\n",
    "        for hour in range(3, 21, 1):\n",
    "            filename = 'day' + str(day) + 'hour' + str(hour) + '.pickle'\n",
    "            with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "                matrix = np.array(pickle.load(f, encoding='latin1'))\n",
    "\n",
    "            if isinstance(wind_matrix, int):\n",
    "                wind_matrix = matrix[:, :, np.newaxis]\n",
    "            else:\n",
    "                wind_matrix = np.concatenate([wind_matrix, matrix[:, :, np.newaxis]], axis=2)\n",
    "        with open(os.path.join(dirpath, 'wind_matrix' + str(vs) + '.pickle'), 'wb') as f:\n",
    "            pickle.dump(wind_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start day 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: max, day6 done\n",
      "start day 7\n",
      "mode: max, day7 done\n",
      "start day 8\n",
      "mode: max, day8 done\n",
      "start day 9\n",
      "mode: max, day9 done\n",
      "start day 10\n",
      "mode: max, day10 done\n"
     ]
    }
   ],
   "source": [
    "for day in range(6, 11, 1):\n",
    "    print ('start day {}'.format(day))\n",
    "    df = pd.DataFrame()\n",
    "    for vs in range(1, 6, 1):\n",
    "        file_dir = '../dataset/lgb_cv' + str(vs)\n",
    "        if df.shape[0] == 0:\n",
    "            df = pd.read_csv(os.path.join(file_dir, 'wind_lightgbm_day' + str(day) + '.csv'), index_col=[0])\n",
    "        else:\n",
    "            df = pd.concat([df, pd.read_csv(os.path.join(file_dir, 'wind_lightgbm_day' + str(day) + '.csv'), index_col=[0])[['predict_final']]], axis=1)\n",
    "    df.columns = ['xid', 'yid', 'hour', 'predict_final1', 'predict_final2', 'predict_final3',\n",
    "           'predict_final4', 'predict_final5']\n",
    "    df['max_val'] = df[['predict_final1', 'predict_final2', 'predict_final3',\n",
    "       'predict_final4', 'predict_final5']].apply(np.max, axis=1)\n",
    "    \n",
    "    for mode in ['max']:\n",
    "        dir_name = '../dataset/'\n",
    "        for i in range(3, 21):\n",
    "            day_hour = df[df['hour'] == i]\n",
    "            df_real_day = day_hour.copy()\n",
    "            xid = df_real_day[df_real_day['hour'] == i]['xid']\n",
    "            yid = df_real_day[df_real_day['hour'] == i]['yid'] \n",
    "            wind = df_real_day[df_real_day['hour'] == i][mode + '_val']\n",
    "            df_test_hour = pd.DataFrame({'xid': list(xid),\n",
    "                          'yid': list(yid),\n",
    "                          'wind': list(wind)})\n",
    "            pt = df_test_hour.pivot_table(index='xid', columns='yid', values='wind', aggfunc=np.sum)\n",
    "            with open(dir_name + '/day' + str(day) + 'hour'+ str(i) +'.pickle', 'wb') as f:\n",
    "                pickle.dump(pt, f)\n",
    "        print ('mode: {}, day{} done'.format(mode, day))\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day in range(6, 11, 1):\n",
    "    dirpath ='../dataset/day' + str(day)\n",
    "    wind_matrix = -1\n",
    "    for hour in range(3, 21, 1):\n",
    "        filename = 'day' + str(day) + 'hour' + str(hour) + '.pickle'\n",
    "        with open(os.path.join('../dataset', filename), 'rb') as f:\n",
    "            matrix = np.array(pickle.load(f, encoding='latin1'))\n",
    "\n",
    "        if isinstance(wind_matrix, int):\n",
    "            wind_matrix = matrix[:, :, np.newaxis]\n",
    "        else:\n",
    "            wind_matrix = np.concatenate([wind_matrix, matrix[:, :, np.newaxis]], axis=2)\n",
    "    with open(os.path.join(dirpath, 'wind_matrix_lgb_cv.pickle'), 'wb') as f:\n",
    "        pickle.dump(wind_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
