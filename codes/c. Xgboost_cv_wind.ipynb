{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Temporal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1:  get index_list for get the temporal feature faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNextHourIndexByCurHour(df_day, hour):\n",
    "    if hour == 20:\n",
    "        hour = 19\n",
    "    index_start = (hour - 3 + 1)*548*421\n",
    "    index_end = (hour - 3 + 2)*548*421\n",
    "    return range(index_start, index_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPreviousHourIndexByCurHour(df_day, hour):\n",
    "    if hour == 3:\n",
    "        hour = 4\n",
    "    index_start = (hour - 3 - 1)*548*421\n",
    "    index_end = (hour - 3)*548*421\n",
    "    return range(index_start, index_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rain_day1 = pd.read_csv('../dataset/rainfall_data_day1.csv')\n",
    "\n",
    "previous_hour_list = []\n",
    "for hour in range(3, 21):\n",
    "    previous_hour_list.append(getPreviousHourIndexByCurHour(df_rain_day1, hour))\n",
    "previous_hour_list = np.ravel(previous_hour_list)\n",
    "\n",
    "next_hour_list = []\n",
    "for hour in range(3, 21):\n",
    "    next_hour_list.append(getNextHourIndexByCurHour(df_rain_day1, hour))\n",
    "next_hour_list = np.ravel(next_hour_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Generate Training & Testing Sets Add Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/wind_data_add_temporal_feature_day1.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day2.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day3.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day4.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day5.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day6.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day7.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day8.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day9.csv already exists\n",
      "../dataset/wind_data_add_temporal_feature_day10.csv already exists\n"
     ]
    }
   ],
   "source": [
    "for day in range(1, 11):\n",
    "    if os.path.exists('../dataset/wind_data_add_temporal_feature_day'+ str(day) +'.csv'):\n",
    "        print ('../dataset/wind_data_add_temporal_feature_day'+ str(day) +'.csv already exists')\n",
    "        continue\n",
    "    print((\"day {} is begin\").format(str(day)))\n",
    "    start = time.time()\n",
    "    df_day = pd.read_csv('../dataset/wind_data_day'+ str(day) + '.csv')\n",
    "    feature = ['predict_' + str(i) for i in range (1, 11, 1)]\n",
    "    df_day_previous_hour = df_day.iloc[previous_hour_list][feature]\n",
    "    feature_previous_hour = ['predict_' + str(i) + '_previous_hour' for i in range (1, 11, 1)]\n",
    "    df_day_previous_hour.columns = feature_previous_hour\n",
    "\n",
    "    df_day_next_hour = df_day.iloc[next_hour_list][feature]\n",
    "    feature_next_hour = ['predict_' + str(i) + '_next_hour' for i in range (1, 11, 1)]\n",
    "    df_day_next_hour.columns = feature_next_hour\n",
    "                 \n",
    "    df_day_previous_hour = df_day_previous_hour.reset_index(drop=True)\n",
    "    df_day_next_hour = df_day_next_hour.reset_index(drop=True)\n",
    "\n",
    "    df_day_concat = pd.concat([df_day, df_day_previous_hour, df_day_next_hour], axis=1)  \n",
    "    df_day_concat.to_csv('../dataset/wind_data_add_temporal_feature_day'+ str(day) +'.csv', index=False)\n",
    "    del df_day, df_day_concat, df_day_previous_hour, df_day_next_hour\n",
    "    print((\"day {} is done\").format(str(day)))\n",
    "    cost_time = time.time() - start\n",
    "    print((\"cost time: {0:.2f} min\").format(cost_time/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 2 is read\n",
      "day 2 is concated\n",
      "day 3 is read\n",
      "day 3 is concated\n",
      "day 4 is read\n",
      "day 4 is concated\n",
      "day 5 is read\n",
      "day 5 is concated\n",
      "[0]\tvalidation_0-rmse:10.7779\n",
      "Will train until validation_0-rmse hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-rmse:8.63273\n",
      "[2]\tvalidation_0-rmse:6.91272\n",
      "[3]\tvalidation_0-rmse:5.55743\n",
      "[4]\tvalidation_0-rmse:4.47872\n",
      "[5]\tvalidation_0-rmse:3.62283\n",
      "[6]\tvalidation_0-rmse:2.95911\n",
      "[7]\tvalidation_0-rmse:2.43055\n",
      "[8]\tvalidation_0-rmse:2.02968\n",
      "[9]\tvalidation_0-rmse:1.72073\n",
      "[10]\tvalidation_0-rmse:1.49979\n",
      "[11]\tvalidation_0-rmse:1.34225\n",
      "[12]\tvalidation_0-rmse:1.23051\n",
      "[13]\tvalidation_0-rmse:1.15829\n",
      "[14]\tvalidation_0-rmse:1.11062\n",
      "[15]\tvalidation_0-rmse:1.08058\n",
      "[16]\tvalidation_0-rmse:1.06253\n",
      "[17]\tvalidation_0-rmse:1.05199\n",
      "[18]\tvalidation_0-rmse:1.04631\n",
      "[19]\tvalidation_0-rmse:1.04343\n",
      "[20]\tvalidation_0-rmse:1.04214\n",
      "[21]\tvalidation_0-rmse:1.04215\n",
      "[22]\tvalidation_0-rmse:1.04212\n",
      "[23]\tvalidation_0-rmse:1.04248\n",
      "[24]\tvalidation_0-rmse:1.04243\n",
      "[25]\tvalidation_0-rmse:1.04292\n",
      "[26]\tvalidation_0-rmse:1.04323\n",
      "[27]\tvalidation_0-rmse:1.044\n",
      "[28]\tvalidation_0-rmse:1.04438\n",
      "[29]\tvalidation_0-rmse:1.04489\n",
      "[30]\tvalidation_0-rmse:1.04532\n",
      "[31]\tvalidation_0-rmse:1.04558\n",
      "[32]\tvalidation_0-rmse:1.04581\n",
      "[33]\tvalidation_0-rmse:1.04617\n",
      "[34]\tvalidation_0-rmse:1.04615\n",
      "[35]\tvalidation_0-rmse:1.04637\n",
      "[36]\tvalidation_0-rmse:1.04647\n",
      "[37]\tvalidation_0-rmse:1.04533\n",
      "[38]\tvalidation_0-rmse:1.04463\n",
      "[39]\tvalidation_0-rmse:1.04458\n",
      "[40]\tvalidation_0-rmse:1.04461\n",
      "[41]\tvalidation_0-rmse:1.04373\n",
      "[42]\tvalidation_0-rmse:1.04376\n",
      "Stopping. Best iteration:\n",
      "[22]\tvalidation_0-rmse:1.04212\n",
      "\n",
      "cost time: 10.080576308568318 min\n",
      "day 1 is read\n",
      "day 1 is concated\n",
      "day 3 is read\n",
      "day 3 is concated\n",
      "day 4 is read\n",
      "day 4 is concated\n",
      "day 5 is read\n",
      "day 5 is concated\n",
      "[0]\tvalidation_0-rmse:10.7087\n",
      "Will train until validation_0-rmse hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-rmse:8.63215\n",
      "[2]\tvalidation_0-rmse:6.97461\n",
      "[3]\tvalidation_0-rmse:5.65943\n",
      "[4]\tvalidation_0-rmse:4.62772\n",
      "[5]\tvalidation_0-rmse:3.80469\n",
      "[6]\tvalidation_0-rmse:3.16194\n",
      "[7]\tvalidation_0-rmse:2.66492\n",
      "[8]\tvalidation_0-rmse:2.28735\n",
      "[9]\tvalidation_0-rmse:2.00521\n",
      "[10]\tvalidation_0-rmse:1.80274\n",
      "[11]\tvalidation_0-rmse:1.65645\n",
      "[12]\tvalidation_0-rmse:1.55896\n",
      "[13]\tvalidation_0-rmse:1.48828\n",
      "[14]\tvalidation_0-rmse:1.44146\n",
      "[15]\tvalidation_0-rmse:1.40936\n",
      "[16]\tvalidation_0-rmse:1.38646\n",
      "[17]\tvalidation_0-rmse:1.37055\n",
      "[18]\tvalidation_0-rmse:1.35975\n",
      "[19]\tvalidation_0-rmse:1.35041\n",
      "[20]\tvalidation_0-rmse:1.34419\n",
      "[21]\tvalidation_0-rmse:1.3438\n",
      "[22]\tvalidation_0-rmse:1.34231\n",
      "[23]\tvalidation_0-rmse:1.34126\n",
      "[24]\tvalidation_0-rmse:1.34022\n",
      "[25]\tvalidation_0-rmse:1.33967\n",
      "[26]\tvalidation_0-rmse:1.33957\n",
      "[27]\tvalidation_0-rmse:1.33937\n",
      "[28]\tvalidation_0-rmse:1.33861\n",
      "[29]\tvalidation_0-rmse:1.33819\n",
      "[30]\tvalidation_0-rmse:1.34027\n",
      "[31]\tvalidation_0-rmse:1.34046\n",
      "[32]\tvalidation_0-rmse:1.34042\n",
      "[33]\tvalidation_0-rmse:1.34052\n",
      "[34]\tvalidation_0-rmse:1.34051\n",
      "[35]\tvalidation_0-rmse:1.34012\n",
      "[36]\tvalidation_0-rmse:1.33975\n",
      "[37]\tvalidation_0-rmse:1.33911\n",
      "[38]\tvalidation_0-rmse:1.33896\n",
      "[39]\tvalidation_0-rmse:1.33932\n",
      "[40]\tvalidation_0-rmse:1.3385\n",
      "[41]\tvalidation_0-rmse:1.33943\n",
      "[42]\tvalidation_0-rmse:1.33903\n",
      "[43]\tvalidation_0-rmse:1.33972\n",
      "[44]\tvalidation_0-rmse:1.33954\n",
      "[45]\tvalidation_0-rmse:1.33974\n",
      "[46]\tvalidation_0-rmse:1.33944\n",
      "[47]\tvalidation_0-rmse:1.33991\n",
      "[48]\tvalidation_0-rmse:1.33994\n",
      "[49]\tvalidation_0-rmse:1.33922\n",
      "Stopping. Best iteration:\n",
      "[29]\tvalidation_0-rmse:1.33819\n",
      "\n",
      "cost time: 11.848078207174938 min\n",
      "day 1 is read\n",
      "day 1 is concated\n",
      "day 2 is read\n",
      "day 2 is concated\n",
      "day 4 is read\n",
      "day 4 is concated\n",
      "day 5 is read\n",
      "day 5 is concated\n",
      "[0]\tvalidation_0-rmse:7.47802\n",
      "Will train until validation_0-rmse hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-rmse:5.98392\n",
      "[2]\tvalidation_0-rmse:4.80457\n",
      "[3]\tvalidation_0-rmse:3.86471\n",
      "[4]\tvalidation_0-rmse:3.11535\n",
      "[5]\tvalidation_0-rmse:2.52293\n",
      "[6]\tvalidation_0-rmse:2.05617\n",
      "[7]\tvalidation_0-rmse:1.686\n",
      "[8]\tvalidation_0-rmse:1.40005\n",
      "[9]\tvalidation_0-rmse:1.18342\n",
      "[10]\tvalidation_0-rmse:1.01278\n",
      "[11]\tvalidation_0-rmse:0.893235\n",
      "[12]\tvalidation_0-rmse:0.805551\n",
      "[13]\tvalidation_0-rmse:0.740937\n",
      "[14]\tvalidation_0-rmse:0.693407\n",
      "[15]\tvalidation_0-rmse:0.662226\n",
      "[16]\tvalidation_0-rmse:0.638667\n",
      "[17]\tvalidation_0-rmse:0.621413\n",
      "[18]\tvalidation_0-rmse:0.61024\n",
      "[19]\tvalidation_0-rmse:0.59962\n",
      "[20]\tvalidation_0-rmse:0.592157\n",
      "[21]\tvalidation_0-rmse:0.587316\n",
      "[22]\tvalidation_0-rmse:0.584119\n",
      "[23]\tvalidation_0-rmse:0.581446\n",
      "[24]\tvalidation_0-rmse:0.577839\n",
      "[25]\tvalidation_0-rmse:0.576811\n",
      "[26]\tvalidation_0-rmse:0.576999\n",
      "[27]\tvalidation_0-rmse:0.576506\n",
      "[28]\tvalidation_0-rmse:0.575569\n",
      "[29]\tvalidation_0-rmse:0.574964\n",
      "[30]\tvalidation_0-rmse:0.5733\n",
      "[31]\tvalidation_0-rmse:0.573494\n",
      "[32]\tvalidation_0-rmse:0.57308\n",
      "[33]\tvalidation_0-rmse:0.57287\n",
      "[34]\tvalidation_0-rmse:0.571765\n",
      "[35]\tvalidation_0-rmse:0.572052\n",
      "[36]\tvalidation_0-rmse:0.572485\n",
      "[37]\tvalidation_0-rmse:0.570917\n",
      "[38]\tvalidation_0-rmse:0.570189\n",
      "[39]\tvalidation_0-rmse:0.570076\n",
      "[40]\tvalidation_0-rmse:0.56996\n",
      "[41]\tvalidation_0-rmse:0.570185\n",
      "[42]\tvalidation_0-rmse:0.571215\n",
      "[43]\tvalidation_0-rmse:0.571606\n",
      "[44]\tvalidation_0-rmse:0.571685\n",
      "[45]\tvalidation_0-rmse:0.571399\n",
      "[46]\tvalidation_0-rmse:0.571515\n",
      "[47]\tvalidation_0-rmse:0.571499\n",
      "[48]\tvalidation_0-rmse:0.571286\n",
      "[49]\tvalidation_0-rmse:0.571482\n",
      "[50]\tvalidation_0-rmse:0.571274\n",
      "[51]\tvalidation_0-rmse:0.571158\n",
      "[52]\tvalidation_0-rmse:0.571124\n",
      "[53]\tvalidation_0-rmse:0.571091\n",
      "[54]\tvalidation_0-rmse:0.571215\n",
      "[55]\tvalidation_0-rmse:0.571835\n",
      "[56]\tvalidation_0-rmse:0.570958\n",
      "[57]\tvalidation_0-rmse:0.57088\n",
      "[58]\tvalidation_0-rmse:0.570931\n",
      "[59]\tvalidation_0-rmse:0.570794\n",
      "[60]\tvalidation_0-rmse:0.570801\n",
      "Stopping. Best iteration:\n",
      "[40]\tvalidation_0-rmse:0.56996\n",
      "\n",
      "cost time: 14.955408998330434 min\n",
      "day 1 is read\n",
      "day 1 is concated\n",
      "day 2 is read\n",
      "day 2 is concated\n",
      "day 3 is read\n",
      "day 3 is concated\n",
      "day 5 is read\n",
      "day 5 is concated\n",
      "[0]\tvalidation_0-rmse:11.7184\n",
      "Will train until validation_0-rmse hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-rmse:9.46186\n",
      "[2]\tvalidation_0-rmse:7.64468\n",
      "[3]\tvalidation_0-rmse:6.19488\n",
      "[4]\tvalidation_0-rmse:5.0232\n",
      "[5]\tvalidation_0-rmse:4.10567\n",
      "[6]\tvalidation_0-rmse:3.39852\n",
      "[7]\tvalidation_0-rmse:2.86127\n",
      "[8]\tvalidation_0-rmse:2.43619\n",
      "[9]\tvalidation_0-rmse:2.12691\n",
      "[10]\tvalidation_0-rmse:1.89558\n",
      "[11]\tvalidation_0-rmse:1.72565\n",
      "[12]\tvalidation_0-rmse:1.60964\n",
      "[13]\tvalidation_0-rmse:1.5295\n",
      "[14]\tvalidation_0-rmse:1.47622\n",
      "[15]\tvalidation_0-rmse:1.44081\n",
      "[16]\tvalidation_0-rmse:1.41499\n",
      "[17]\tvalidation_0-rmse:1.39786\n",
      "[18]\tvalidation_0-rmse:1.38472\n",
      "[19]\tvalidation_0-rmse:1.38043\n",
      "[20]\tvalidation_0-rmse:1.37554\n",
      "[21]\tvalidation_0-rmse:1.37255\n",
      "[22]\tvalidation_0-rmse:1.36579\n",
      "[23]\tvalidation_0-rmse:1.36397\n",
      "[24]\tvalidation_0-rmse:1.36381\n",
      "[25]\tvalidation_0-rmse:1.36326\n",
      "[26]\tvalidation_0-rmse:1.36252\n",
      "[27]\tvalidation_0-rmse:1.36165\n",
      "[28]\tvalidation_0-rmse:1.36284\n",
      "[29]\tvalidation_0-rmse:1.36273\n",
      "[30]\tvalidation_0-rmse:1.36185\n",
      "[31]\tvalidation_0-rmse:1.36115\n",
      "[32]\tvalidation_0-rmse:1.36044\n",
      "[33]\tvalidation_0-rmse:1.36089\n",
      "[34]\tvalidation_0-rmse:1.36112\n",
      "[35]\tvalidation_0-rmse:1.36061\n",
      "[36]\tvalidation_0-rmse:1.36044\n",
      "[37]\tvalidation_0-rmse:1.36026\n",
      "[38]\tvalidation_0-rmse:1.36054\n",
      "[39]\tvalidation_0-rmse:1.36054\n",
      "[40]\tvalidation_0-rmse:1.36087\n",
      "[41]\tvalidation_0-rmse:1.36051\n",
      "[42]\tvalidation_0-rmse:1.36107\n",
      "[43]\tvalidation_0-rmse:1.36061\n",
      "[44]\tvalidation_0-rmse:1.36032\n",
      "[45]\tvalidation_0-rmse:1.36054\n",
      "[46]\tvalidation_0-rmse:1.36173\n",
      "[47]\tvalidation_0-rmse:1.36251\n",
      "[48]\tvalidation_0-rmse:1.36066\n",
      "[49]\tvalidation_0-rmse:1.36038\n",
      "[50]\tvalidation_0-rmse:1.36031\n",
      "[51]\tvalidation_0-rmse:1.36118\n",
      "[52]\tvalidation_0-rmse:1.36113\n",
      "[53]\tvalidation_0-rmse:1.36127\n",
      "[54]\tvalidation_0-rmse:1.36128\n",
      "[55]\tvalidation_0-rmse:1.36138\n",
      "[56]\tvalidation_0-rmse:1.36158\n",
      "[57]\tvalidation_0-rmse:1.36046\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-rmse:1.36026\n",
      "\n",
      "cost time: 13.838069649537404 min\n",
      "day 1 is read\n",
      "day 1 is concated\n",
      "day 2 is read\n",
      "day 2 is concated\n",
      "day 3 is read\n",
      "day 3 is concated\n",
      "day 4 is read\n",
      "day 4 is concated\n",
      "[0]\tvalidation_0-rmse:11.2069\n",
      "Will train until validation_0-rmse hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-rmse:9.03303\n",
      "[2]\tvalidation_0-rmse:7.26621\n",
      "[3]\tvalidation_0-rmse:5.85234\n",
      "[4]\tvalidation_0-rmse:4.73573\n",
      "[5]\tvalidation_0-rmse:3.84355\n",
      "[6]\tvalidation_0-rmse:3.13887\n",
      "[7]\tvalidation_0-rmse:2.57993\n",
      "[8]\tvalidation_0-rmse:2.13871\n",
      "[9]\tvalidation_0-rmse:1.79486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalidation_0-rmse:1.53147\n",
      "[11]\tvalidation_0-rmse:1.32983\n",
      "[12]\tvalidation_0-rmse:1.18186\n",
      "[13]\tvalidation_0-rmse:1.07094\n",
      "[14]\tvalidation_0-rmse:0.991191\n",
      "[15]\tvalidation_0-rmse:0.931014\n",
      "[16]\tvalidation_0-rmse:0.889919\n",
      "[17]\tvalidation_0-rmse:0.861501\n",
      "[18]\tvalidation_0-rmse:0.840272\n",
      "[19]\tvalidation_0-rmse:0.8262\n",
      "[20]\tvalidation_0-rmse:0.816687\n",
      "[21]\tvalidation_0-rmse:0.808613\n",
      "[22]\tvalidation_0-rmse:0.804448\n",
      "[23]\tvalidation_0-rmse:0.800753\n",
      "[24]\tvalidation_0-rmse:0.798427\n",
      "[25]\tvalidation_0-rmse:0.796511\n",
      "[26]\tvalidation_0-rmse:0.794357\n",
      "[27]\tvalidation_0-rmse:0.793738\n",
      "[28]\tvalidation_0-rmse:0.793008\n",
      "[29]\tvalidation_0-rmse:0.792189\n",
      "[30]\tvalidation_0-rmse:0.79133\n",
      "[31]\tvalidation_0-rmse:0.791091\n",
      "[32]\tvalidation_0-rmse:0.790897\n",
      "[33]\tvalidation_0-rmse:0.790457\n",
      "[34]\tvalidation_0-rmse:0.790213\n",
      "[35]\tvalidation_0-rmse:0.790065\n",
      "[36]\tvalidation_0-rmse:0.790033\n",
      "[37]\tvalidation_0-rmse:0.789743\n",
      "[38]\tvalidation_0-rmse:0.789597\n",
      "[39]\tvalidation_0-rmse:0.789679\n",
      "[40]\tvalidation_0-rmse:0.789924\n",
      "[41]\tvalidation_0-rmse:0.789673\n",
      "[42]\tvalidation_0-rmse:0.789772\n",
      "[43]\tvalidation_0-rmse:0.789585\n",
      "[44]\tvalidation_0-rmse:0.789576\n",
      "[45]\tvalidation_0-rmse:0.789595\n",
      "[46]\tvalidation_0-rmse:0.789617\n",
      "[47]\tvalidation_0-rmse:0.788969\n",
      "[48]\tvalidation_0-rmse:0.789082\n",
      "[49]\tvalidation_0-rmse:0.788913\n",
      "[50]\tvalidation_0-rmse:0.789073\n",
      "[51]\tvalidation_0-rmse:0.789309\n",
      "[52]\tvalidation_0-rmse:0.788616\n",
      "[53]\tvalidation_0-rmse:0.788539\n",
      "[54]\tvalidation_0-rmse:0.788267\n",
      "[55]\tvalidation_0-rmse:0.788299\n",
      "[56]\tvalidation_0-rmse:0.788447\n",
      "[57]\tvalidation_0-rmse:0.7886\n",
      "[58]\tvalidation_0-rmse:0.788591\n",
      "[59]\tvalidation_0-rmse:0.788743\n",
      "[60]\tvalidation_0-rmse:0.788834\n",
      "[61]\tvalidation_0-rmse:0.788889\n",
      "[62]\tvalidation_0-rmse:0.788567\n",
      "[63]\tvalidation_0-rmse:0.788603\n",
      "[64]\tvalidation_0-rmse:0.788534\n",
      "[65]\tvalidation_0-rmse:0.788173\n",
      "[66]\tvalidation_0-rmse:0.788061\n",
      "[67]\tvalidation_0-rmse:0.78814\n",
      "[68]\tvalidation_0-rmse:0.788199\n",
      "[69]\tvalidation_0-rmse:0.788317\n",
      "[70]\tvalidation_0-rmse:0.788341\n",
      "[71]\tvalidation_0-rmse:0.788433\n",
      "[72]\tvalidation_0-rmse:0.788258\n",
      "[73]\tvalidation_0-rmse:0.788017\n",
      "[74]\tvalidation_0-rmse:0.788116\n",
      "[75]\tvalidation_0-rmse:0.788118\n",
      "[76]\tvalidation_0-rmse:0.787748\n",
      "[77]\tvalidation_0-rmse:0.787743\n",
      "[78]\tvalidation_0-rmse:0.787694\n",
      "[79]\tvalidation_0-rmse:0.788068\n",
      "[80]\tvalidation_0-rmse:0.788109\n",
      "[81]\tvalidation_0-rmse:0.788415\n",
      "[82]\tvalidation_0-rmse:0.788367\n",
      "[83]\tvalidation_0-rmse:0.788334\n",
      "[84]\tvalidation_0-rmse:0.788386\n",
      "[85]\tvalidation_0-rmse:0.788451\n",
      "[86]\tvalidation_0-rmse:0.788507\n",
      "[87]\tvalidation_0-rmse:0.78871\n",
      "[88]\tvalidation_0-rmse:0.788378\n",
      "[89]\tvalidation_0-rmse:0.788384\n",
      "[90]\tvalidation_0-rmse:0.788582\n",
      "[91]\tvalidation_0-rmse:0.788628\n",
      "[92]\tvalidation_0-rmse:0.788625\n",
      "[93]\tvalidation_0-rmse:0.788482\n",
      "[94]\tvalidation_0-rmse:0.788042\n",
      "[95]\tvalidation_0-rmse:0.788072\n",
      "[96]\tvalidation_0-rmse:0.787985\n",
      "[97]\tvalidation_0-rmse:0.787908\n",
      "[98]\tvalidation_0-rmse:0.788087\n",
      "Stopping. Best iteration:\n",
      "[78]\tvalidation_0-rmse:0.787694\n",
      "\n",
      "cost time: 22.440452031294505 min\n"
     ]
    }
   ],
   "source": [
    "for cur_day in range(1, 6):\n",
    "    df_train = pd.DataFrame()\n",
    "    for day in [x for x in range(1, 6) if x != cur_day]:\n",
    "        df_train_day = pd.read_csv('../dataset/wind_data_add_temporal_feature_day'+ str(day) +'.csv')\n",
    "        print (\"day %d is read\" % day)\n",
    "        df_train_day = df_train_day.sample(frac=0.25)\n",
    "        df_train = pd.concat([df_train, df_train_day], axis= 0, ignore_index=True)\n",
    "        print (\"day %d is concated\" % day)\n",
    "    del df_train_day\n",
    "    df_test = pd.read_csv('../dataset/wind_data_add_temporal_feature_day' + str(cur_day) + '.csv')\n",
    "    df_test = df_test.sample(frac=0.25)\n",
    "    df_train = df_train.drop(['xid', 'yid', 'hour'], axis=1)\n",
    "    X_train = df_train.drop('real', axis=1).values\n",
    "    y_train = df_train['real'].values\n",
    "\n",
    "    df_test = df_test.drop(['xid', 'yid', 'hour'], axis=1)\n",
    "    X_test = df_test.drop('real', axis=1).values\n",
    "    y_test = df_test['real'].values\n",
    "    del df_train, df_test\n",
    "    xgbReg = XGBRegressor(max_depth=5,\n",
    "                            learning_rate=0.2,\n",
    "                            n_estimators=1000,\n",
    "                            silent=False,\n",
    "                            objective='reg:linear',\n",
    "                            nthread=-1,\n",
    "                            gamma=0,\n",
    "                            min_child_weight=1,\n",
    "                            max_delta_step=0,\n",
    "                            subsample=0.8,\n",
    "                            colsample_bytree=0.7,\n",
    "                            colsample_bylevel=1,\n",
    "                            reg_alpha=0,\n",
    "                            reg_lambda=1,\n",
    "                            scale_pos_weight=1,\n",
    "                            seed=1440,\n",
    "                            missing=None)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    xgbReg.fit(X_train, y_train, eval_metric='rmse', verbose=True, eval_set=[(X_test, y_test)], early_stopping_rounds=20)\n",
    "    cost_time = time.time() - start\n",
    "    print(\"cost time: %s min\"  % str(cost_time/60.0))\n",
    "\n",
    "    with open('../dataset/xgb_time_' + str(cur_day) +'.pickle', 'wb') as f:\n",
    "        pickle.dump(xgbReg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. predict wind in testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_paths = ['../dataset/xgb_time_' + str(model) + '.pickle' for model in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 6 is begin\n",
      "cost: 1.402747102578481 min\n",
      "day 7 is begin\n",
      "cost: 1.4846476753552755 min\n",
      "day 8 is begin\n",
      "cost: 1.3717480778694153 min\n",
      "day 9 is begin\n",
      "cost: 1.276911973953247 min\n",
      "day 10 is begin\n",
      "cost: 1.3189071496327718 min\n"
     ]
    }
   ],
   "source": [
    "for day in range(6, 11):\n",
    "    print (\"day %d is begin\" % day)\n",
    "    start = time.time()\n",
    "    df_test = pd.read_csv('../dataset/wind_data_add_temporal_feature_day'+ str(day) +'.csv')\n",
    "    df_xgb_space_model = pd.DataFrame()\n",
    "    df_xgb_space_model = pd.concat([df_xgb_space_model, df_test[['xid', 'yid', 'hour']]], axis=1)\n",
    "    for model_path in model_paths:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            xgb_space_model = pickle.load(f)\n",
    "        X_train = df_test.drop(['xid', 'yid', 'hour'], axis=1).values\n",
    "        y_pred = xgb_space_model.predict(X_train)\n",
    "        column = 'model' + model_path[9:10]\n",
    "        df_xgb_space_model[column] = y_pred\n",
    "    df_xgb_space_model.to_csv('../dataset/wind_xgb_cv_time_day'+ str(day) +'.csv', index=False)\n",
    "    cost = time.time() - start\n",
    "    print (\"cost: %s min\" % str(cost/60.0))\n",
    "    del df_test, df_xgb_space_model, X_train, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the max value of each cv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day in range(6, 11):\n",
    "    df_day = pd.read_csv('../dataset/wind_xgb_cv_time_day'+ str(day) +'.csv')\n",
    "    cols = df_day.columns\n",
    "    df_day['predict_final'] = df_day[cols[3:]].max(axis=1)\n",
    "    df_day.to_csv('../dataset/wind_xgb_cv_time_day'+ str(day) +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. generate wind_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start day6\n",
      "cost 0.528s\n",
      "cost 0.388s\n",
      "cost 0.377s\n",
      "cost 0.380s\n",
      "cost 0.382s\n",
      "cost 0.536s\n",
      "cost 0.474s\n",
      "cost 0.421s\n",
      "cost 0.404s\n",
      "cost 0.403s\n",
      "cost 0.429s\n",
      "cost 0.471s\n",
      "cost 0.385s\n",
      "cost 0.433s\n",
      "cost 0.500s\n",
      "cost 0.395s\n",
      "cost 0.383s\n",
      "cost 0.399s\n",
      "start day7\n",
      "cost 0.406s\n",
      "cost 0.395s\n",
      "cost 0.396s\n",
      "cost 0.394s\n",
      "cost 0.411s\n",
      "cost 0.412s\n",
      "cost 0.678s\n",
      "cost 0.411s\n",
      "cost 0.414s\n",
      "cost 0.388s\n",
      "cost 0.406s\n",
      "cost 0.393s\n",
      "cost 0.412s\n",
      "cost 0.408s\n",
      "cost 0.404s\n",
      "cost 0.406s\n",
      "cost 0.406s\n",
      "cost 0.445s\n",
      "start day8\n",
      "cost 0.401s\n",
      "cost 0.400s\n",
      "cost 0.449s\n",
      "cost 0.396s\n",
      "cost 0.496s\n",
      "cost 0.531s\n",
      "cost 0.686s\n",
      "cost 0.464s\n",
      "cost 0.397s\n",
      "cost 0.436s\n",
      "cost 0.620s\n",
      "cost 0.605s\n",
      "cost 0.456s\n",
      "cost 0.408s\n",
      "cost 0.420s\n",
      "cost 0.393s\n",
      "cost 0.393s\n",
      "cost 0.546s\n",
      "start day9\n",
      "cost 0.389s\n",
      "cost 0.382s\n",
      "cost 0.381s\n",
      "cost 0.419s\n",
      "cost 0.397s\n",
      "cost 0.572s\n",
      "cost 0.385s\n",
      "cost 0.400s\n",
      "cost 0.410s\n",
      "cost 0.402s\n",
      "cost 0.427s\n",
      "cost 0.389s\n",
      "cost 0.454s\n",
      "cost 0.401s\n",
      "cost 0.407s\n",
      "cost 0.417s\n",
      "cost 0.405s\n",
      "cost 0.490s\n",
      "start day10\n",
      "cost 0.390s\n",
      "cost 0.378s\n",
      "cost 1.069s\n",
      "cost 0.462s\n",
      "cost 0.524s\n",
      "cost 0.407s\n",
      "cost 0.388s\n",
      "cost 0.405s\n",
      "cost 0.405s\n",
      "cost 0.409s\n",
      "cost 0.401s\n",
      "cost 0.395s\n",
      "cost 0.406s\n",
      "cost 0.391s\n",
      "cost 0.426s\n",
      "cost 0.413s\n",
      "cost 0.492s\n",
      "cost 0.468s\n"
     ]
    }
   ],
   "source": [
    "for day in range(6, 11, 1):\n",
    "    print ('start day{}'.format(day))\n",
    "    df_test = pd.read_csv('../dataset/wind_xgb_cv_time_day' + str(day) + '.csv')\n",
    "    for i in range(3, 21):\n",
    "        t1 = time.time()\n",
    "        day_hour = df_test[df_test['hour'] == i]\n",
    "        df_real_day = day_hour.copy()\n",
    "        xid = df_real_day[df_real_day['hour'] == i]['xid']\n",
    "        yid = df_real_day[df_real_day['hour'] == i]['yid'] \n",
    "        wind = df_real_day[df_real_day['hour'] == i]['predict_final']\n",
    "        df_test_hour = pd.DataFrame({'xid': list(xid),\n",
    "                      'yid': list(yid),\n",
    "                      'wind': list(wind)})\n",
    "        pt = df_test_hour.pivot_table(index='xid', columns='yid', values='wind', aggfunc=np.sum)\n",
    "        store_dir = '../dataset/'\n",
    "        if not os.path.exists(store_dir):\n",
    "            os.mkdir(store_dir)\n",
    "        with open(os.path.join(store_dir, 'day' + str(day) + 'hour'+ str(i) +'.pickle'), 'wb') as f:\n",
    "            pickle.dump(pt, f)\n",
    "        t2 = time.time()\n",
    "        print ('cost {0:.3f}s'.format(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day in range(6, 11):\n",
    "    dirpath ='../dataset/'\n",
    "    wind_matrix = -1\n",
    "    for hour in range(3, 21, 1):\n",
    "        filename = 'day'+ str(day) +'hour' + str(hour) + '.pickle'\n",
    "        with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "            matrix = np.array(pickle.load(f, encoding='latin1'))\n",
    "\n",
    "        if isinstance(wind_matrix, int):\n",
    "            wind_matrix = matrix[:, :, np.newaxis]\n",
    "        else:\n",
    "            wind_matrix = np.concatenate([wind_matrix, matrix[:, :, np.newaxis]], axis=2)\n",
    "    dirpath ='../dataset/day' + str(day)\n",
    "    with open(os.path.join(dirpath, 'wind_matrix_xgb.pickle'), 'wb') as f:\n",
    "        pickle.dump(wind_matrix, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
